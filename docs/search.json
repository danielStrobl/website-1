[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Quarto",
    "section": "",
    "text": "The overarching goal of Quarto is to make the process of creating and collaborating on scientific and technical documents dramatically better. We hope to do this in several dimensions:\n\nCreate a writing and publishing environment with great integrated tools for technical content. We want to make authoring with embedded code, equations, figures, complex diagrams, interactive widgets, citations, cross references, and the myriad other special requirements of scientific discourse straightforward and productive for everyone.\nHelp authors take full advantage of the web as a connected, interactive platform for communications, while still providing the ability to create excellent printed output from the same document source. Researchers shouldn’t need to choose between LaTeX, MS Word, and HTML but rather be able to author documents that target all of them at the same time.\nMake reproducible research and publications the norm rather than the exception. Reproducibility requires that the code and data required to create a manuscript are an integrated part of it. However, this isn’t often straightforward in practice—Quarto aims to make it easier to adopt a reproducible workflow than not.\n\nQuarto is open source software licensed under the GNU GPL v2. We believe that it’s better for everyone if the tools used for research and science are free and open. Reproducibility, widespread sharing of knowledge and techniques, and the leveling of the playing field by eliminating cost barriers are but a few of the shared benefits of free software in science."
  },
  {
    "objectID": "about.html#project",
    "href": "about.html#project",
    "title": "About Quarto",
    "section": "Project",
    "text": "Project\nAt the core of Quarto is Pandoc, a powerful and flexible document processing tool. Quarto adds a number of facilities to Pandoc aimed at scientific and technical publishing, including:\n\nEmbedding code and output from Python, R, and JavaScript via integration with Jupyter, Knitr, and Observable.\nA variety of extensions to Pandoc markdown useful for technical writing including cross-references, sub-figures, layout panels, hoverable citations and footnotes, callouts, and more.\nA project system for rendering groups of documents at once, sharing options across documents, and producing aggregate output like websites and books.\n\nDevelopment of Quarto is sponsored by RStudio, PBC, where we previously created a similar system (R Markdown) that shared the same goals, but was targeted principally at users of the R language. The same core team works on both Quarto and R Markdown:\n\nJ.J. Allaire (@jjallaire)\nChristophe Dervieux (@cderv)\nCarlos Scheidegger (@cscheid)\nCharles Teague (@dragonstyle)\nYihui Xie (@yihui)\n\nWith Quarto, we are hoping to bring these tools to a much wider audience.\nQuarto is a registered trademark of RStudio. Please see our trademark policy for guidelines on usage of the Quarto trademark."
  },
  {
    "objectID": "about.html#contribute",
    "href": "about.html#contribute",
    "title": "About Quarto",
    "section": "Contribute",
    "text": "Contribute\nYou can contribute to Quarto in many ways:\n\nBy opening issues to provide feedback and share ideas.\nBy submitting Pull Request (PR) to fix opened issues\nBy submitting Pull Request (PR) to suggest new features (it is considered good practice to open an issue for discussion before working on a pull request for a new feature).\n\nPlease be mindful of our code of conduct as you interact with other community members.\n\nPull Requests\nPull requests are very welcome! Here’s how to contribute via PR:\n\nFork the repository, clone it locally, and make your changes in a new branch specific to the PR. For example:\n# clone your fork\n$ git clone https://github.com/<username>/quarto-cli\n\n# configure for your platform (./configure-macos.sh, ./configure-linux.sh, or ./configure-windows.cmd)\n$ cd quarto-cli\n$ ./configure-macos.sh\n\n# checkout a new branch\n$ git checkout -b feature/newthing\nFor significant changes (e.g more than small bug fixes), ensure that you have signed the individual or corporate contributor agreement as appropriate. You can send the signed copy to jj@rstudio.com.\nSubmit the pull request. It is ok to submit as draft in your are still working on it but would like some feedback from us. It always good to share in the open that you are working on it.\n\nWe’ll try to be as responsive as possible in reviewing and accepting pull requests."
  },
  {
    "objectID": "documentation/guide/temp/output-naming.html",
    "href": "documentation/guide/temp/output-naming.html",
    "title": "Output Naming",
    "section": "",
    "text": "The default naming convention of output files is '$id.$key.$arg.$ext', where:\n\n$id is the first element of the event tuple.\n$key is the name of the component (e.g. remove_comments). This can be overridden using .run(key: \"foo\").\n$arg is the name of the output argument (e.g. output).\n$ext is an extension extracted from the example or default of the argument, if it exists.\n\nYou can manually specify the output file names by adding it as an argument.\nExample:\n  // Concatenate TSVs into one\n  //   (String, {input: List[File]}) -> (String, File)\n  | combine_columns.run(\n    args: [ output: \"output.tsv\" ]\n  )\nYou can use a map to ensure that the output name does make use of the id:\n  // Remove comments from TSV\n  //   (String, File) -> (String, File)\n  | remove_comments.run(\n    map: { tup -> [ tup[0], [ input: tup[1], output: \"output_${tup[0]}.tsv\" ] ] }\n  )"
  },
  {
    "objectID": "documentation/guide/temp/vdsl3-basics.html",
    "href": "documentation/guide/temp/vdsl3-basics.html",
    "title": "VDSL3 Basics",
    "section": "",
    "text": "At one point, we (at Data Intuitive) thought about what would make for an “ideal” Nextflow module (cfr. DIFlow by Toni Verbeiren). We found out that, in order for the Nextflow module to have the properties that we wanted, the component would need to contain a lot of boilerplate code.\nLuckily, Viash can be used to generate the boilerplate code for you. To do so, we just need to take our script and add some metadata to it.\n\nViash allows easy prototyping of reusable pipeline components. From Cannoodt et al. 2021 arXiv:2110.11494.\nIn this section, we will use Viash to generate Nextflow modules that behave similarly to the ones created in the previous section, but with some distinct advantages. Since we believe that these Nextflow modules are so different from the original Nextflow DSL2 processes and workflows, we named them Viash DSL3 modules, or VDSL3 modules for short."
  },
  {
    "objectID": "documentation/guide/temp/vdsl3-basics.html#how-to-create-and-use-a-vdsl3-module",
    "href": "documentation/guide/temp/vdsl3-basics.html#how-to-create-and-use-a-vdsl3-module",
    "title": "VDSL3 Basics",
    "section": "How to create and use a VDSL3 module",
    "text": "How to create and use a VDSL3 module\nBelow shows a comparison of the original remove_comments process and a Viash component that has the same functionality.\nTODO: ask to create these and explain\nVDSL3 Viash component\n\n\nconfig.vsh.yaml\n\nfunctionality:\n  name: remove_comments\n  namespace: vdsl3_tutorial\n  arguments:\n    - name: \"--input\"\n      alternatives: [ \"-i\" ]\n      type: file\n      required: true\n      example: \"file.tsv\"\n    - name: \"--output\"\n      alternatives: [ \"-o\" ]\n      type: file\n      required: true\n      direction: output\n      example: \"file.tsv\"\n  resources:\n  - type: bash_script\n    path: ./script.sh\nplatforms:\n  - type: nextflow\n    variant: vdsl3\n    directives:\n      container: ubuntu:20.04\n\n\n\nscript.sh\n\n#!/bin/bash\n\ngrep -v '^#' \"$par_input\" > \"$par_output\"\n\n\nGenerating a VDSL3 module from a Viash config\nThere are definitely some similarities between the original Nextflow process and the Viash component. To actually make use of the new component inside of our Nextflow pipeline, we first need to export the Viash component into a VDSL3 module by running the following command:\nviash build src/vdsl3_tutorial/remove_comments/config.vsh.yaml \\\n  -o target/nextflow/vdsl3_tutorial/remove_comments\nThis results in the creation of the following files:\ntree target/nextflow/vdsl3_tutorial/remove_comments\ntarget/nextflow/vdsl3_tutorial/remove_comments\n├── main.nf\n└── nextflow.config\n\n0 directories, 2 files\n\n\nRun module as a standalone\nA VDSL3 module can actually already be used as a standalone Nextflow pipeline (albeit a very small one).\nYou can display the documentation using the help argument:\nnextflow run target/nextflow/vdsl3_tutorial/remove_comments/main.nf --help\nN E X T F L O W  ~  version 22.04.3\nLaunching `target/nextflow/vdsl3_tutorial/remove_comments/main.nf` [distracted_stallman] DSL2 - revision: 8de4c7c8eb\nremove_comments\n\nOptions:\n    --input\n        type: file, required parameter\n        example: file.tsv\n\n    --output\n        type: file, required parameter, output\n        example: file.tsv\nRunning the component results in the following output:\nnextflow run target/nextflow/vdsl3_tutorial/remove_comments/main.nf \\\n  --input \"data/file1.tsv\" \\\n  --publishDir output/\nN E X T F L O W  ~  version 22.04.3\nLaunching `target/nextflow/vdsl3_tutorial/remove_comments/main.nf` [wise_jang] DSL2 - revision: 8de4c7c8eb\nWARN: Key for module 'remove_comments' is duplicated.\n\ninput: [run, [input:/home/runner/work/viash_nxf_course/viash_nxf_course/data/file1.tsv]]\n[7e/8cd91f] Submitted process > remove_comments:remove_comments_process1\noutput: [run, /home/runner/work/viash_nxf_course/viash_nxf_course/work/7e/8cd91f5274d3e46188ec62106d8ecc/run.remove_comments.output.tsv]\n\n\nUse module in a pipeline\nMore importantly, a VDSL3 module can be included as part of a Nextflow pipeline as follows:\nContents of workflows/300-first_vdsl_pipeline/main.nf:\nnextflow.enable.dsl=2\n\ntargetDir = \"../../target/nextflow\"\n\ninclude { remove_comments } from \"$targetDir/vdsl3_tutorial/remove_comments/main.nf\"\n\nworkflow {\n  Channel.fromPath(params.input)\n    | map{ file -> [ file.baseName, file ] }\n    | view{ file -> \"Input: $file\" }\n    | remove_comments\n    | view{ file -> \"Output: $file\" }\n}\n\n\n\n\n\n\nNote\n\n\n\nThe ability to include a module is part of the Nextflow DSL2 functionality.\n\n\nnextflow run workflows/300-first_vdsl_pipeline/main.nf \\\n  --input \"data/file?.tsv\" --publishDir output\nN E X T F L O W  ~  version 22.04.3\nLaunching `workflows/300-first_vdsl_pipeline/main.nf` [lethal_mandelbrot] DSL2 - revision: 1c8e8aacbe\nInput: [file1, /home/runner/work/viash_nxf_course/viash_nxf_course/data/file1.tsv]\nInput: [file2, /home/runner/work/viash_nxf_course/viash_nxf_course/data/file2.tsv]\n[9c/505943] Submitted process > remove_comments:remove_comments_process (1)\n[f4/540a13] Submitted process > remove_comments:remove_comments_process (2)\nOutput: [file1, /home/runner/work/viash_nxf_course/viash_nxf_course/work/9c/505943f6280fd9d054b9937d2ca13e/file1.remove_comments.output.tsv]\nOutput: [file2, /home/runner/work/viash_nxf_course/viash_nxf_course/work/f4/540a13f599819c7681550901544ac9/file2.remove_comments.output.tsv]"
  },
  {
    "objectID": "documentation/guide/temp/adapting-modules.html",
    "href": "documentation/guide/temp/adapting-modules.html",
    "title": "Adapting Modules",
    "section": "",
    "text": "One major benefit of VDSL3 modules in comparison to standard Nextflow processes is that the directives (e.g. whether or not to publish output files) can be defined dynamically using the .run() function.\n\n\nTo actually publish the results, we need to define a publishDir directive. Additionally, we also set specific memory and cpu usage requirements per process.\n\n\n<...>\n  // Concatenate TSVs into one\n  //   (String, {input: List[File]}) -> (String, File)\n  | combine_columns\n\n\n\n<...>\n  // Concatenate TSVs into one\n  //   (String, {input: List[File]}) -> (String, File)\n  | combine_columns.run(\n    directives: [\n      publishDir: params.publishDir,\n      cpus: 4,\n      memory: \"10G\"\n    ]\n  )\n\n\n\n\nThe .run() function also provides some functionality for modifying incoming events. For example, you can change the value of a parameter by passing a map to args. More complicated modifications can be found in the appendix.\n\n\n<...>\n  // Extract single column from TSV\n  //   (String, File) -> (String, File)\n  | take_column\n\n\n\n<...>\n  // Extract single column from TSV\n  //   (String, File) -> (String, File)\n  | take_column.run(\n    args: [ column: 1 ]\n  )"
  },
  {
    "objectID": "documentation/guide/temp/realistic-pipeline.html",
    "href": "documentation/guide/temp/realistic-pipeline.html",
    "title": "Realistic Nextflow Pipeline",
    "section": "",
    "text": "This version of the pipeline represents a more realistic use-case of typical Nextflow bioinformatics pipelines.\n\nIt has a mixture of Bash, Python and R components\nThe data flow now also features a join, where all events are merged into a single event.\n\nBefore showing the new Nextflow pipeline, let’s first introduce the Python and R components.\n\n\nThis component subsets an incoming tsv file by extracting a certain column from the file. The take_column component is similar to the take_second_column component from the previous section, except we converted it to Python and made the column an optional parameter.\nContents of src/vdsl3_tutorial/take_column/:\n\n\nconfig.vsh.yaml\n\nfunctionality:\n  name: take_column\n  namespace: vdsl3_tutorial\n  arguments:\n    - name: \"--input\"\n      alternatives: [ \"-i\" ]\n      type: file\n      required: true\n    - name: \"--output\"\n      alternatives: [ \"-o\" ]\n      type: file\n      required: true\n      direction: output\n    - name: \"--column\"\n      type: integer\n      required: false\n      default: 2\n  resources:\n  - type: python_script\n    path: ./script.py\nplatforms:\n  - type: nextflow\n    variant: vdsl3\n    directives:\n      container: amancevice/pandas:slim\n\n\n\nscript.py\n\nimport pandas as pd\n\n## VIASH START\npar = {\n    \"input\": \"data/file1.tsv\",\n    \"column\": 2,\n    \"output\": \"temp/foo\"\n}\n## VIASH END\n\n# read the tsv file\ntab = pd.read_csv(par[\"input\"], sep=\"\\t\", comment=\"#\")\n\n# subset a column\ntab_filt = tab.iloc[:, par[\"column\"]-1]\n\n# write to file\ntab_filt.to_csv(par[\"output\"], index=False)\n\n\n\n\nThis component combines multiple tsv files into one by concatenating all of the columns together. It assumes each incoming tsv file has an equal number of rows.\nContents of src/vdsl3_tutorial/combine_columns/:\n\n\nconfig.vsh.yaml\n\nfunctionality:\n  name: combine_columns\n  namespace: vdsl3_tutorial\n  arguments:\n    - name: \"--input\"\n      alternatives: [ \"-i\" ]\n      type: file\n      multiple: true\n      required: true\n    - name: \"--output\"\n      alternatives: [ \"-o\" ]\n      type: file\n      required: true\n      direction: output\n  resources:\n    - type: r_script\n      path: ./script.R\nplatforms:\n  - type: nextflow\n    variant: vdsl3\n    directives:\n      container: rocker/r-ver:4.1\n\n\n\nscript.R\n\n## VIASH START\npar <- list(\n    input = c(\"data/file1.tsv\", \"data/file2.tsv\"),\n    output = \"temp/foo.tsv\"\n)\n## VIASH END\n\nouts <- lapply(par$input, function(file) {\n  read.delim(file, comment.char = \"#\", sep = \"\\t\", header = FALSE)\n})\n\ntable <- do.call(cbind, outs)\n\nwrite.table(table, par$output, col.names = FALSE, sep = \"\\t\")\n\n\n\n\nIn the previous sections, we created three Viash components.\nContents of src/vdsl3_tutorial/:\nsrc/vdsl3_tutorial/\n├── combine_columns\n│   ├── config.vsh.yaml\n│   └── script.R\n├── remove_comments\n│   ├── config.vsh.yaml\n│   └── script.sh\n└── take_column\n    ├── config.vsh.yaml\n    └── script.py\n\n3 directories, 6 files\nRather than generate VDSL3 modules from each Viash component individually using the viash build command, we can build all of the components in a namespace (ns) using the viash ns build command in one go. The resulting files will be stored under target/<platform>/<namespace>/<component_name>.\nviash ns build -q vdsl3_tutorial\nExporting take_column (vdsl3_tutorial) =nextflow=> target/nextflow/vdsl3_tutorial/take_column\nExporting combine_columns (vdsl3_tutorial) =nextflow=> target/nextflow/vdsl3_tutorial/combine_columns\nExporting remove_comments (vdsl3_tutorial) =nextflow=> target/nextflow/vdsl3_tutorial/remove_comments\nThe target directory now contains our Nextflow modules:\nContents of target:\ntarget/\n└── nextflow\n    └── vdsl3_tutorial\n        ├── combine_columns\n        │   ├── main.nf\n        │   └── nextflow.config\n        ├── remove_comments\n        │   ├── main.nf\n        │   └── nextflow.config\n        └── take_column\n            ├── main.nf\n            └── nextflow.config\n\n5 directories, 6 files\n\n\n\nDuring a more complicated Nextflow workflow, it can be useful to keep track of what transformations are being performed at critical steps of the pipeline. In this case, we simply labelled all steps.\nContents of workflows/310-realistic_pipeline/main.nf:\nnextflow.enable.dsl=2\n\ntargetDir = \"../../target/nextflow\"\n\ninclude { remove_comments } from \"$targetDir/vdsl3_tutorial/remove_comments/main.nf\"\ninclude { take_column } from \"$targetDir/vdsl3_tutorial/take_column/main.nf\"\ninclude { combine_columns } from \"$targetDir/vdsl3_tutorial/combine_columns/main.nf\"\n\nworkflow {\n  Channel.fromPath(params.input)\n  \n    // Assign unique ID to each event\n    //   File -> (String, File)\n    | map{ file -> [ file.baseName, file ] }\n    \n    // Remove comments from TSV\n    //   (String, File) -> (String, File)\n    | remove_comments\n\n    // Extract single column from TSV\n    //   (String, File) -> (String, File)\n    | take_column\n\n    // Combine all events into a single List event\n    //   (String, File)* -> List[(String, File)]\n    | toList()\n\n    // Add unique ID to tuple\n    //   List[(String, File)] -> (String, {input: List[File]})\n    | map{ tups -> \n      files = tups.collect{id, file -> file}\n      [ \"combined\", [ input: files ] ] \n    }\n\n    // Concatenate TSVs into one\n    //   (String, {input: List[File]}) -> (String, File)\n    | combine_columns\n\n    // View channel contents\n    | view{ file -> \"Output: $file\" }\n}\nIn terms of a marble diagram, the toList() operator can be represented as in Figure 1.\n\n\n\nFigure 1: The data flow of the toList() part of workflows/310-realistic_pipeline/main.nf.\n\n\nWe are dealing with tuples in VDSL3 IO, so the above would turn into:\n\n\n\nFigure 2: The data flow of the toList() in combination with tuples.\n\n\n\n\n\nWhen we run the updated pipeline, we can see that the execution seems to run correctly.\nnextflow run workflows/310-realistic_pipeline/main.nf \\\n  --input \"data/file?.tsv\" --publishDir output\nN E X T F L O W  ~  version 22.04.3\nLaunching `workflows/310-realistic_pipeline/main.nf` [peaceful_kare] DSL2 - revision: 65be946be4\n[26/03f3d6] Submitted process > remove_comments:remove_comments_process (2)\n[39/b4aecb] Submitted process > remove_comments:remove_comments_process (1)\n[e9/0e5f7f] Submitted process > take_column:take_column_process (1)\n[cc/f65b62] Submitted process > take_column:take_column_process (2)\n[47/12ee1c] Submitted process > combine_columns:combine_columns_process\nOutput: [combined, /home/runner/work/viash_nxf_course/viash_nxf_course/work/47/12ee1cf9a37c5450db605199c8abf7/combined.combine_columns.output]\nEach process seems to have finished correctly (exit code 0).\nHowever, no output was created in the output directory. In fact, the output directory wasn’t even created when running the pipeline.\ntree output\noutput [error opening dir]\n\n0 directories, 0 files\nThe reason for this is that VDSL3 modules are meant to be reusable components. However, at the time of writing the Viash component (i.e. the config.vsh.yaml) you might not know whether the component is the last step of the pipeline, so it does not make sense to decide whether a component’s output will be published or not."
  },
  {
    "objectID": "documentation/guide/temp/realistic-pipeline.html#benefits-of-vdsl3",
    "href": "documentation/guide/temp/realistic-pipeline.html#benefits-of-vdsl3",
    "title": "Realistic Nextflow Pipeline",
    "section": "Benefits of VDSL3",
    "text": "Benefits of VDSL3\nThis guide introduced some key concepts of VDSL3 modules. In comparison to standard Nextflow modules, a VDSL3 module offers:\n\nReadable but flexible pipelines\nAutomatic file naming to avoid naming conflicts\nFlexible directives\nEasy polylingualism (integrates well with custom Docker container builds, see next guide)\nFree standalone CLI and --help\nOverridable arguments with defaults\n\nOne limitation of VDSL3 is that Nextflow processes are able to accept tuples of any format whatsoever, whereas VDLS3 modules have a more rigid interface (see appendix). However, we argue that this limitation is actually a benefit, as it makes modules more interchangeable and have argument defaults.\nIn the next guide, we’ll see that generating VDSL3 modules is actually just one aspect of Viash."
  },
  {
    "objectID": "documentation/guide/temp/nextflow-basics.html",
    "href": "documentation/guide/temp/nextflow-basics.html",
    "title": "Nextflow Basics",
    "section": "",
    "text": "Nextflow is a popular DSL-based workflow manager with exemplary portability, reproducibility and scalability:\n\nPortability means that one can write the pipeline once, using the Nextflow DSL and run it on different platforms, i.e. what Nextflow calls executors ranging from a simple laptop to cluster systems running hundreds or thousands of nodes.\nDepending on the executor, computations can be scaled out to multiple nodes automatically\nNextflow automatically keeps a log of parameters and intermediate results providing a foundation for reproducible workflows."
  },
  {
    "objectID": "documentation/guide/temp/nextflow-basics.html#nextflow-dialects",
    "href": "documentation/guide/temp/nextflow-basics.html#nextflow-dialects",
    "title": "Nextflow Basics",
    "section": "Nextflow dialects",
    "text": "Nextflow dialects\nOver the past year, the flexibility of the Nextflow DSL has evolved significantly.\n\nDSL1: The original Nextflow syntax, using a more ‘imperative’ programming approach.\nDSL2: A set of built-in helper classes which allow pipelines to be built in more ‘functional’ way.\nThe nf-core project uses a combination of DSL2 and custom Groovy helper classes to reduce some of the boilerplate code.\nVDSL3: An extension of DSL2 which uses to Viash to make Nextflow functional and more ‘batteries included’, see also VDSL3."
  },
  {
    "objectID": "documentation/guide/temp/tuples.html",
    "href": "documentation/guide/temp/tuples.html",
    "title": "Modifying Tuples",
    "section": "",
    "text": "Viash offers sugar syntax to modify incoming arguments in various ways:\nManual map:\n  // Assign unique ID to each event\n  //   File -> (String, File)\n  | map{ file -> [ file.baseName, file ] }\n  \n  // Remove comments from TSV\n  //   (String, File) -> (String, File)\n  | remove_comments\nMap included in .run():\n  // Remove comments from TSV\n  // Inner map adds unique ID to tuple\n  //   File -> (String, File)\n  | remove_comments.run(\n    map: { file -> [ file.baseName, file ] }\n  )\nPossible tuple modification arguments:\n\nmap: Apply a map over the incoming tuple.\nmapId: Apply a map over the ID element of a tuple (i.e. the first element).\nmapData: Apply a map over the data element of a tuple (i.e. the second element).\nmapPassthrough: Apply a map over the passthrough elements of a tuple (i.e. the tuple excl. the first two elements).\nrenameKeys: Rename keys in the data field of the tuple (i.e. the second element).\nargs: Fixed argument values which will be added to each tuple in the channel.\ndebug: Whether or not to print debug messages.\n\nSetting debug: true will help you understand how events are modified at any stage of your pipeline. Effectively, it triggers a few view() statements throughout the execution of the module.\nprocess 'take_column' input tuple: [file1, work/46/6bffd3749913149f7fcbbe2d1af7c6/file1.remove_comments.output.tsv]\nprocess 'take_column' processed tuple: [file1, [input:work/46/6bffd3749913149f7fcbbe2d1af7c6/file1.remove_comments.output.tsv]]\nprocess 'take_column' output tuple: [file1, work/44/c3f2d7dd291ea394b3334f3117b45b/file1.take_column.output]"
  },
  {
    "objectID": "documentation/guide/temp/simple-pipeline.html",
    "href": "documentation/guide/temp/simple-pipeline.html",
    "title": "DSL2 Pipeline",
    "section": "",
    "text": "Nextflow DSL2 borrows some elements from event-driven functional programming. As a matter of fact, one could argue that Nextflow’s Channel concept being strictly speaking an example of the DataFlow Programming Model can in fact be regarded as an implementation of a (albeit limited) Functional Reactive Programming library.\nContents of workflows/200-first_nextflow_pipeline/main.nf:\nworkflow {\n  Channel.fromList( [\" a \", \"   b\", \"  c\", \"d  \"] )\n    | map{ elem -> elem.trim() }\n    | view\n}\nThis workflow consists of three steps:\n\nAn channel is created containing 4 strings\nA map which removes spaces around the strings (.trim()).\nA view which displays the contents of the events to the user\n\nThe pipe operator (|) allows connecting steps (which might generate and/or consume events) together.\nQuite a lot is going on in these 3 lines of code. Before we dissect this in detail, let us first explore the Channel or usually called (reactive) stream concept.\n\n\nBelow you can see an illustration of how an empty channel can be created and how events can be put on that channel. The technical term for putting events on the channel is bind.\nworkflow {\n  ch = Channel.empty()\n\n  ch << \" a \"\n  ch << \"   b\"\n  ch << \"  c\"\n  ch << \"d \"\n\n  ch\n    | map{ elem -> elem.trim() }\n    | subscribe{ print \"$it\" }\n}\nThis pipeline definition does exactly the same as our previous example and just aims to describe what is happening under the hood. The Channel.fromList() used in the first example is an illustration of a Channel factory method.\nThe data flow of channels (and later processes) can be visualised as shown in Figure 1.\n\n\n\nFigure 1: The data flow of workflows/200-first_nextflow_pipeline/main.nf.\n\n\n\n\n\nNextflow is a DSL on top of the Groovy programming language, so you can use whatever Groovy code to manipulate Channel events in however way you like[^2].\n\n[ 1, 2, 3 ]: A list of integers\n[ a: 1, b: 2, c: 3 ]: A hash map (dictionary, named list)\n{ elem -> elem.trim() }: An anonymous function, aka closure\n{ it.trim() }: The same anonymous function with the implicit variable it\na ? b : c: If a then b else c\n\nHere is a cheat sheet on Groovy syntax.\n\n\n\nLet’s see what happens when we run the pipeline above using Nextflow:\nnextflow run workflows/200-first_nextflow_pipeline/main.nf\nN E X T F L O W  ~  version 22.04.3\nLaunching `workflows/200-first_nextflow_pipeline/main.nf` [evil_pare] DSL2 - revision: cfd75d221a\na\nb\nc\nd"
  },
  {
    "objectID": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html",
    "href": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html",
    "title": "Pipeline Basics",
    "section": "",
    "text": "explain this guide will go over the basics of VDSL3 and how to use modules inside of a Nextflow pipeline reference to the nextflow website for the basics of nextflow’s Groovy syntax"
  },
  {
    "objectID": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html#vdsl3",
    "href": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html#vdsl3",
    "title": "Pipeline Basics",
    "section": "VDSL3",
    "text": "VDSL3\nexplain what VDSL3 is and how it builds upon"
  },
  {
    "objectID": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html#creating-the-module",
    "href": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html#creating-the-module",
    "title": "Pipeline Basics",
    "section": "Creating the module",
    "text": "Creating the module\nNextflow works with modules to run scripts and handle their input and output, so the first step is generating a Nextflow module from a Viash component\n\nCreating the component\ncreate a new folder named basic_pipeline, add a new folder to it named src download the remove_comments component files and add them to src\nDownload config.vsh.yaml\nDownload script.sh\n\n\nBuilding the Nextflow module\nviash build src/remove_comments/config.vsh.yaml -o target/remove_comments"
  },
  {
    "objectID": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html#creating-the-pipeline",
    "href": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html#creating-the-pipeline",
    "title": "Pipeline Basics",
    "section": "Creating the pipeline",
    "text": "Creating the pipeline\nAdd main.nf:\ntargetDir = \"./target\" // 1\n\ninclude { remove_comments } from \"$targetDir/remove_comments/main.nf\" // 2\n\nworkflow {\n  Channel.fromPath(params.input) // 3\n    | map{ file -> [ file.baseName, file ] } // 4\n    | view{ file -> \"Input: $file\" } // 5\n    | remove_comments.run( // 6\n      auto: [ publish: true ]\n      )\n    | view{ file -> \"Output: $file\" } // 7\n}\nHere’s an overview of this Nextflow script:\n\ntarget dir where the modules are located\ninclude the remove_comments module from the remove_comments/main.nf script\nCreate a channel based on the input parameter’s path\nTake the tuple list and map it to the [ file.baseName, file ] fornmat\nPrint the input tuple to the console\nRun the remove_comments module with auto publishing enabled using the auto directive\nPrint the output tuple to the console\n\nrun the pipeline\nnextflow run main.nf --input \"data/sample.tsv\" --publishDir output\nN E X T F L O W  ~  version 22.04.3\nLaunching `main.nf` [curious_gates] DSL2 - revision: 3e22e3038c\nexecutor >  local (1)\n[2a/5df658] process > remove_comments:remove_comments_process (1) [100%] 1 of 1 ✔\nInput: [sample, /home/blackdragonbe/GitHub/new_website/basic_pipeline/data/sample.tsv]\nOutput: [sample, /home/blackdragonbe/GitHub/new_website/basic_pipeline/work/2a/5df6584524e26995953a4eaec97136/sample.remove_comments.output.tsv]"
  },
  {
    "objectID": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html#whats-next",
    "href": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-basics.html#whats-next",
    "title": "Pipeline Basics",
    "section": "What’s next?",
    "text": "What’s next?\nthe pipeline in this guide was the bare minimum to learn more about\nAdvanced Pipeline"
  },
  {
    "objectID": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-advanced.html",
    "href": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-advanced.html",
    "title": "Advanced Pipeline",
    "section": "",
    "text": "explain this pipeline is a more realistic example of a typical use-case of a Nextflow bioinformatics pipeline as it has a mixture of scripting languages used and a join is used to merge all events"
  },
  {
    "objectID": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-advanced.html#creating-the-modules",
    "href": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-advanced.html#creating-the-modules",
    "title": "Advanced Pipeline",
    "section": "Creating the modules",
    "text": "Creating the modules\nThis pipeline uses three Nextflow modules which you’ll generate using Viash components:\n\nremove_comments\ntake_columns\ncombine_columns\n\nThe sections below describe how to create these in preparation for the pipeline.\n\nCreating the remove_comments component\nDownload config.vsh.yaml\nDownload script.sh\n\n\nCreating the take_column component\nThis component subsets an incoming tsv file by extracting a certain column from the file.\nDownload config.vsh.yaml\nDownload script.py\n\n\nCreating the combine_columns component\nDownload config.vsh.yaml\nDownload script.py"
  },
  {
    "objectID": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-advanced.html#building-the-modules",
    "href": "documentation/guide/data-workflow/nextflow-pipeline/pipeline-advanced.html#building-the-modules",
    "title": "Advanced Pipeline",
    "section": "Building the modules",
    "text": "Building the modules\nThe basic pipeline guide describes how to generate an individual Nextflow module using the viash build command, but there’s a better way when it comes to"
  },
  {
    "objectID": "documentation/guide/component/creation/nextflow.html",
    "href": "documentation/guide/component/creation/nextflow.html",
    "title": "Nextflow",
    "section": "",
    "text": "This guide explains how to create a Viash component from scratch that targets the Nextflow platform. For a general overview of Viash components, take a look at the Viash Basics guide."
  },
  {
    "objectID": "documentation/guide/component/creation/nextflow.html#creating-a-viash-component",
    "href": "documentation/guide/component/creation/nextflow.html#creating-a-viash-component",
    "title": "Nextflow",
    "section": "Creating a Viash component",
    "text": "Creating a Viash component\n\nAdding a Viash config\ncreate folder named nextflow_component, add src/remove_comments dir create config.vsh.yaml and add to src/remove_comments\nadd this\nfunctionality:\n  name: remove_comments\n  arguments:\n    - name: \"--input\"\n      alternatives: [ \"-i\" ]\n      type: file\n      required: true\n      example: \"file.tsv\"\n    - name: \"--output\"\n      alternatives: [ \"-o\" ]\n      type: file\n      required: true\n      direction: output\n      example: \"file.tsv\"\n  resources:\n  - type: bash_script\n    path: ./script.sh\nplatforms:\n  - type: nextflow\n    variant: vdsl3\n    directives:\n      container: ubuntu:20.04\nshort description of what this does\nfocus on platforms section, explain vdsl3 and directives\nsingle resource needed, a script\n\n\nWriting the script\nadd simple script\n#!/bin/bash\n\ngrep -v '^#' \"$par_input\" > \"$par_output\"\nyou now have this structure which makes up a component\nnextflow_component\n└── src\n    └── remove_comments\n        ├── config.vsh.yaml\n        └── script.sh"
  },
  {
    "objectID": "documentation/guide/component/creation/nextflow.html#running-the-viash-component",
    "href": "documentation/guide/component/creation/nextflow.html#running-the-viash-component",
    "title": "Nextflow",
    "section": "Running the Viash component",
    "text": "Running the Viash component\nIn contrast to native and Docker based components, a Nextflow based component cannot be ran by using the viash run command. These types of components require you to use viash build first to generate a Nextflow module and run that module using nextflow run. See Building and Running Nextflow for more information."
  },
  {
    "objectID": "documentation/guide/component/creation/native.html",
    "href": "documentation/guide/component/creation/native.html",
    "title": "Native",
    "section": "",
    "text": "BashC#JavascriptPythonScalaR\n\n\necho \"Hello Bash\"\n\n\necho \"Hello C#\"\n\n\necho \"Hello Javascript\"\n\n\necho \"Hello Python\"\n\n\necho \"Hello Scala\"\n\n\necho \"Hello R\""
  },
  {
    "objectID": "documentation/guide/component/creation/docker.html",
    "href": "documentation/guide/component/creation/docker.html",
    "title": "Docker",
    "section": "",
    "text": "BashC#JavascriptPythonScalaR\n\n\necho \"Hello Bash\"\n\n\necho \"Hello C#\"\n\n\necho \"Hello Javascript\"\n\n\necho \"Hello Python\"\n\n\necho \"Hello Scala\"\n\n\necho \"Hello R\""
  },
  {
    "objectID": "documentation/guide/building-block/nextflow/building-running.html",
    "href": "documentation/guide/building-block/nextflow/building-running.html",
    "title": "Building and Running",
    "section": "",
    "text": "This guide covers how you can can build a Nextflow module to use in your pipeline."
  },
  {
    "objectID": "documentation/guide/building-block/nextflow/building-running.html#building-a-nextflow-vdsl3-module",
    "href": "documentation/guide/building-block/nextflow/building-running.html#building-a-nextflow-vdsl3-module",
    "title": "Building and Running",
    "section": "Building a Nextflow VDSL3 module",
    "text": "Building a Nextflow VDSL3 module\nTo start with, create a Viash component that targets the Nextflow platform as explained in this guide.\nNext, use the viash build command to generate a Nextflow module inside of a target/remove_comments directory:\nviash build src/remove_comments/config.vsh.yaml -o target/remove_comments\nThis will generate two files in the target/remove_comments directory: main.nf and nextflow.config.\nnextflow_component\n├── src\n│   └── remove_comments\n│       ├── config.vsh.yaml\n│       └── script.sh\n└── target\n    └── remove_comments\n        ├── main.nf\n        └── nextflow.config"
  },
  {
    "objectID": "documentation/guide/building-block/nextflow/building-running.html#runing-a-standalone-pipeline",
    "href": "documentation/guide/building-block/nextflow/building-running.html#runing-a-standalone-pipeline",
    "title": "Building and Running",
    "section": "Runing a standalone pipeline",
    "text": "Runing a standalone pipeline\nA VDSL3 module can be run as a small, standalone Nextflow pipeline.\n\nDocumentation\nIt’s often useful to know what arguments a module expects before trying to run it. To display the documentation for a module, run the module with just the --help argument:\nnextflow run target/remove_comments/main.nf --help\nThis will result in output that looks similar to this:\nN E X T F L O W  ~  version 22.04.3\nLaunching `target/remove_comments/main.nf` [admiring_carlsson] DSL2 - revision: 8de4c7c8eb\nremove_comments\n\nOptions:\n    --input\n        type: file, required parameter\n        example: file.tsv\n\n    --output\n        type: file, required parameter, output\n        example: file.tsv\nAs you can see, this module needs a tsv file as its input and it will write the updated file away to a given output path.\n\n\nRunning the module\nTo test out the module by itself, you need a tsv file to remove the comments from. You can download a sample file we provided here:\n\nDownload sample.tsv\nHere are its contents:\n# this is a header      \n# this is also a header     \none     0.11    123\ntwo     0.23    456\nthree   0.35    789\nfour    0.47    123\nPlace sample.tsv file in a new directory named data, alongside the src and target directories.\nnextflow_component\n├── data\n│   └── sample.tsv\n├── src\n│   └── remove_comments\n│       ├── config.vsh.yaml\n│       └── script.sh\n└── target\n    └── remove_comments\n        ├── main.nf\n        └── nextflow.config\nNow run the module along with the required arguments:\nnextflow run target/remove_comments/main.nf \\\n   --input \"data/sample.tsv\" \\\n   --publishDir output\nBelow is the result:\nN E X T F L O W  ~  version 22.04.3\nLaunching `target/remove_comments/main.nf` [desperate_fermat] DSL2 - revision: 8de4c7c8eb\nWARN: Key for module 'remove_comments' is duplicated.\n\nexecutor >  local (1)\n[2b/17d7a5] process > remove_comments:remove_comments_process1 [100%] 1 of 1 ✔\ninput: [run, [input:/home/user/nextflow_component/data/sample.tsv]]\noutput: [run, /home/user/nextflow_component/work/2b/17d7a50e74d27bc8fd39f098ba06fc/run.remove_comments.output.tsv]\nA new tsv file should’ve been generated now in the output folder named run.remove_comments.output.tsv."
  },
  {
    "objectID": "documentation/guide/building-block/nextflow/building-running.html#whats-next",
    "href": "documentation/guide/building-block/nextflow/building-running.html#whats-next",
    "title": "Building and Running",
    "section": "What’s next?",
    "text": "What’s next?\nto use generated modules inside an actual Nextflow pipeline, see Pipeline Basics"
  },
  {
    "objectID": "documentation/reference/globs.html",
    "href": "documentation/reference/globs.html",
    "title": "Quarto Glob Syntax",
    "section": "",
    "text": "Quarto sometimes allows you to provide a path or paths using glob syntax, providing wildcard expansion and other behavior that makes it simple to match a list of files without having to specify each file individually. Globs may be used:\n\nWhen specifying render targets in Quarto projects (see Render Targets).\nWhen defining resources for Quarto websites (see Site Resources).\nWhen defining documents to include in a listing (see Listing Contents)."
  },
  {
    "objectID": "documentation/reference/globs.html#glob-syntax",
    "href": "documentation/reference/globs.html#glob-syntax",
    "title": "Quarto Glob Syntax",
    "section": "Glob Syntax",
    "text": "Glob Syntax\nThe below is a general reference of the syntax used for globs in Quarto.\n\n* - Matches everything without leaving the path segment.\n{foo,bar} - Matches foo or bar.\n[abcd] - Matches a, b, c or d.\n[a-d] - Matches a, b, c or d.\n[!abcd] - Matches any single character besides a, b, c or d.\n[[:<class>:]] - Matches any character belonging to <class>.\n\n[[:alnum:]] - Matches any digit or letter.\n[[:digit:]abc] - Matches any digit, a, b or c.\nSee https://facelessuser.github.io/wcmatch/glob/#posix-character-classes for a complete list of supported character classes.\n\n\\ - Escapes the next character for an os other than \"windows\".\n` - Escapes the next character for os set to \"windows\".\n/ - Path separator.\n\\ - Additional path separator only for os set to \"windows\".\n?(foo|bar) - Matches 0 or 1 instance of {foo,bar}.\n@(foo|bar) - Matches 1 instance of {foo,bar}. They behave the same.\n*(foo|bar) - Matches n instances of {foo,bar}.\n+(foo|bar) - Matches n > 0 instances of {foo,bar}.\n!(foo|bar) - Matches anything other than {foo,bar}.\n** - Matches any number of any path segments.\n\nMust comprise its entire path segment in the provided glob.\nSee https://www.linuxjournal.com/content/globstar-new-bash-globbing-option."
  },
  {
    "objectID": "documentation/reference/dates.html",
    "href": "documentation/reference/dates.html",
    "title": "Quarto Dates and Date Formatting",
    "section": "",
    "text": "When you write a date for Quarto document, Quarto will attempt to parse a date string by trying a number of standard forms before ultimately attempting to infer the date format. Quarto will try dates formatted as follows, in the following order:\n\nMM/dd/yyyy\nMM-dd-yyyy\nMM/dd/yy\nMM-dd-yy\nyyyy-MM-dd\ndd MM yyyy\nMM dd, yyyy\nYYYY-MM-DDTHH:mm:ssZ\n\nIn addition, you may also provide date keywords, which will provide a dynamic date.\n\n\n\n\n\n\n\nKeyword\nDate\n\n\n\n\ntoday\nThe current local date, with the time portion set to 0.\n\n\nnow\nThe current local date and time.\n\n\nlast-modified\nThe last modified date and time of the file containing the date."
  },
  {
    "objectID": "documentation/reference/dates.html#date-formatting",
    "href": "documentation/reference/dates.html#date-formatting",
    "title": "Quarto Dates and Date Formatting",
    "section": "Date Formatting",
    "text": "Date Formatting\nWhen specifying a date format in Quarto, there are two ways to represent the format that you’d like.\n\nUsing a Date Style\nYou can specify a simple date style which will be used to format the date.\nFor example:\n---\ndate: 03/07/2005\ndate-format: long\n---\nValid styles and examples of the formatted output are as follows:\n\n\n\n\n\n\n\n\nStyle\nDescription\nExample\n\n\n\n\nfull\nA full date that includes the weekday name\nMonday, March 7, 2005\n\n\nlong\nA long date that includes a wide month name\nMarch 7, 2005\n\n\nmedium\nA medium date\nMar 7, 2005\n\n\nshort\nA short date with a numeric month\n3/7/05\n\n\niso\nA short date in ISO format\n2005-03-07\n\n\n\n\n\nUsing a Date Format\nYou can also specify a date format string that will be used to format the date. For example:\n---\ndate: 03/07/2005\ndate-format: \"MMM D, YYYY\"\nThe permissible values in this string include:\n\n\n\n\n\n\n\n\nFormat String\nOutput\nDescription\n\n\n\n\nYY\n18\nTwo-digit year\n\n\nYYYY\n2018\nFour-digit year\n\n\nM\n1-12\nThe month, beginning at 1\n\n\nMM\n01-12\nThe month, 2-digits\n\n\nMMM\nJan-Dec\nThe abbreviated month name\n\n\nMMMM\nJanuary-December\nThe full month name\n\n\nD\n1-31\nThe day of the month\n\n\nDD\n01-31\nThe day of the month, 2-digits\n\n\nd\n0-6\nThe day of the week, with Sunday as 0\n\n\ndd\nSu-Sa\nThe min name of the day of the week\n\n\nddd\nSun-Sat\nThe short name of the day of the week\n\n\ndddd\nSunday-Saturday\nThe name of the day of the week\n\n\nH\n0-23\nThe hour\n\n\nHH\n00-23\nThe hour, 2-digits\n\n\nh\n1-12\nThe hour, 12-hour clock\n\n\nhh\n01-12\nThe hour, 12-hour clock, 2-digits\n\n\nm\n0-59\nThe minute\n\n\nmm\n00-59\nThe minute, 2-digits\n\n\ns\n0-59\nThe second\n\n\nss\n00-59\nThe second, 2-digits\n\n\nSSS\n000-999\nThe millisecond, 3-digits\n\n\nZ\n+05:00\nThe offset from UTC, ±HH:mm\n\n\nZZ\n+0500\nThe offset from UTC, ±HHmm\n\n\nA\nAM PM\n\n\n\na\nam pm\n\n\n\n\nTo escape characters, wrap them in square brackets (e.g. [MM]).\nExample formats and outputs include:\n\n\n\n\n\n\n\nFormat\nOutput\n\n\n\n\nMMM D, YYYY\nMar 7, 2005\n\n\nDD/MM/YYYY\n07/03/2005\n\n\n[YYYYescape] YYYY-MM-DDTHH:mm:ssZ[Z]\nYYYYescape 2005-03-07T00:00:00-05:00Z\n\n\nYYYY-MM-DDTHH:mm:ssZ\n2005-03-07T00:00:00-05:00\n\n\ndddd MMM D, YYYY\nMonday Mar 7, 2005"
  },
  {
    "objectID": "documentation/faq/index.html",
    "href": "documentation/faq/index.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "What can I use Quarto for?\nQuarto® is an open-source scientific and technical publishing system built on Pandoc. You can weave together narrative text and code to produce elegantly formatted output as documents, web pages, blog posts, books and more. \n\n\n\nHow do I install Quarto?\nVisit the Quarto.org Get Started page, which provides installation instructions for Windows, Mac OS, and Linux. \n\n\n\nIs Quarto free to use?\nYes! Quarto is open source with a GPL-2 license. You can use or disseminate it any way that you would any GPL-2 licensed open source software. \n\n\nWhat output formats can Quarto create?\nThere are many output formats available in Quarto. This includes all of the built in Pandoc formats (e.g. HTML, PDF, MS Word, Revealjs, ePub, etc.) as well as various ways to publish multiple documents (websites, blogs, and books). Learn more at Quarto Formats. \n\n\nWhat editing tools can I use with Quarto?\nYou can use a wide variety of tools with Quarto. We have provided documentation for writing and editing Quarto documents in VSCode, JupyterLab, RStudio IDE, or any text editor. Visit the Get Started with Quarto page to install, and then choose your tool for a brief introductory guide.\n\n\nCan I use Jupyter notebooks with Quarto?\nYes! Quarto can render Jupyter notebooks and you can use Jupyter, JupyterLab or any other .ipynb notebook editor with Quarto. You can render existing .ipynb notebooks as-is with Quarto, but adding Quarto-specific output options or a YAML header can enhance the output. Visit theJupyterLab page for more information.\n\n\nWhat programming languages are supported in Quarto?\nThe principal languages supported by Quarto are Python, R, Julia, and Observable JavaScript. Integration with Jupyter also enables the use of many other languages. \nEach Quarto document can be optionally processed by a computational engine (the engine can be manually specified or automatically detected based on the code chunks within). Current engines include Knitr (which is also used by R Markdown and supports a variety of languages including R, Python, and Julia, etc.) and Jupyter (which supports many languages including Python, Julia, and R). See the documentation on Engine Binding for additional details.\n\n\nWhat human languages are supported in Quarto?\nYou can write your Quarto documentation in your human language of choice. The lang document option is used to identify the main language of the document using IETF language tags (following the BCP 47 standard), such as en or en-GB. \n\n\nHow can I share documents and have people comment on them?\nYou can publish Quarto content to various locations. See the user guides for publishing documents and publishing websites  for details on using GitHub Pages, Netlify, RStudio Connect, and other services. with Quarto. Once documents are published you can use  hypothes.is, Utterances, or Giscus for commenting. Learn more in the documentation on commenting.\n\n\nCan I do collaborative editing with Quarto?\nThere is not yet anything specific for collaborative editing in Quarto. You can collaborate on .qmd files in the same way you currently do for any text or code files. \nRStudio Workbench allows for Project Sharing for interactive editing and collaboration on the same document.\n\n\nWhere can I publish Quarto websites?\nThere are a wide variety of ways to publish Quarto websites. Website content is by default written to the _site sub-directory (you can customize this using the output-dir option). Publishing is simply a matter of copying the output directory to a web server or web hosting service.\nThe publishing documentation describes several convenient options for Quarto website deployment including RStudio Connect, Netlify, GitHub Pages, Firebase, Site44, and Amazon S3. We’ll mostly defer to the documentation provided by those various services, but will note any Quarto website specific configuration required.\n\n\nDoes RStudio Connect support Quarto?\nYes! You can publish Quarto content to RStudio Connect v2021.08.0 or later. Quarto has to be enabled as documented in the RStudio Connect admin guide. Connect’s user documentation refers to Quarto.org docs on how to publish from the RStudio IDE. To publish Python-based Quarto content, you can use the rsconnect-python CLI from various locations, including VSCode, JupyterLab or the terminal.\n\n\nWho are the developers of Quarto?\nDevelopment of Quarto is sponsored by RStudio, PBC. The same core team works on both Quarto and R Markdown:\n\nCarlos Scheidegger (@cscheid)\nCharles Teague (@dragonstyle)\nChristophe Dervieux (@cderv)\nJ.J. Allaire (@jjallaire)\nYihui Xie (@yihui)\n\nHere is the full contributors list. Quarto is open source and we welcome contributions in our github repository as well! https://github.com/quarto-dev/quarto-cli.\n\n\nWhy the name Quarto?\nWe wanted to use a name that had meaning in the history of publishing and landed on Quarto, which is the format of a book or pamphlet produced from full sheets printed with eight pages of text, four to a side, then folded twice to produce four leaves. The earliest known European printed book is a Quarto, the Sibyllenbuch, believed to have been printed by Johannes Gutenberg in 1452–53.\n\n\nWhere can I report bugs or request features?\nThanks for finding something and sharing with us! You can file an issue in the Quarto repository https://github.com/quarto-dev/quarto-cli/issues.\n\n\nWhere can I ask questions and discuss using Quarto with others?\nThe best place to ask questions and see what questions other people have is in Quarto discussions (https://github.com/quarto-dev/quarto-cli/discussions)."
  },
  {
    "objectID": "documentation/faq/rmarkdown.html",
    "href": "documentation/faq/rmarkdown.html",
    "title": "FAQ for R Markdown Users",
    "section": "",
    "text": "Quarto sounds similar to R Markdown. What is the difference and why create a new project?\nAt its core, Quarto works the same way as R Markdown: \n\nThe goal of Quarto is to make the process of creating and collaborating on scientific and technical documents dramatically better. Quarto combines the functionality of R Markdown, bookdown, distill, xaringian, etc into a single consistent system with “batteries included” that reflects everything we’ve learned from R Markdown over the past 10 years.\nThe number of languages and runtimes used for scientific discourse is very broad (and the Jupyter ecosystem in particular is extraordinarily popular). Quarto is at its core multi-language and multi-engine (supporting Knitr, Jupyter, and Observable today and potentially other engines tomorrow).\nOn the other hand, R Markdown is fundamentally tied to R which severely limits the number of practitioners it can benefit. Quarto is RStudio’s attempt to bring R Markdown to everyone! Unlike R Markdown, Quarto doesn’t have a dependency or requirement for R. Quarto was developed to be multilingual, beginning with R, Python, Javascript, and Julia, with the idea that it will work even for languages that don’t yet exist.\nWhile it is a “new” system, it should also be noted that it is highly compatible with existing content: you can render most R Markdown documents and Jupyter notebooks unmodified with Quarto. The concept is to make a major, long term investment in reproducible research, while keeping it compatible with existing formats and adaptable to the various environments users work in.\n\n\nIs R Markdown going away? Will my R Markdown documents continue to work?\nR Markdown is not going away! R Markdown is used extensively and continues to work well. It will continue to be actively supported. We’re not leaving R Markdown, we’re expanding our scope. Over the years there have been many feature requests, and rather than implementing them all in R Markdown, for certain features we may refer you to Quarto. Everything that is currently in R Markdown will continue to work and be supported. There are no plans for deprecation.\nRead more about this in Yihui Xie’s blog post With Quarto Coming, is R Markdown Going Away? No.\n\n\nShould I switch from R Markdown to Quarto?\nIf you like using R Markdown, there’s no need to switch! R Markdown will continue to be supported and work as it always has been. You’re welcome to try Quarto if you like, but there’s no need to switch. Some new features may only exist in Quarto, so if you want to use those, then that’s where you would give those a try.  \nWe should emphasize that switching is not imperative. While we don’t plan on major feature initiatives in R Markdown and related packages, we are going to continue to maintain them (smaller improvements and bug fixes) for a long time to come. Furthermore, since Rmd files can in most cases be rendered without modification by Quarto, you can continue using R Markdown and the switching cost will still be minimal whenever you decide to do it. \n\n\nI use X (bookdown, blogdown, etc.). What is the Quarto equivalent?\nHere are the Quarto equivalents for various packages and features of the R Markdown ecosystem (in some cases Quarto equivalents are not yet available but will be later this year):\n\n\n\n\nFeature\nR Markdown\nQuarto\n\n\n\n\nBasic Formats\n\nhtml_document\npdf_document\nword_document\n\n\nhtml\npdf\ndocx\n\n\n\nBeamer\n\nbeamer_presentation\n\n\nbeamer\n\n\n\nPowerPoint\n\npowerpoint_presentation\n\n\npptx\n\n\n\nHTML Slides\n\nxaringan\nioslides\nrevealjs\n\n\nrevealjs\n\n\n\nAdvanced Layout\n\ntufte\ndistill\n\n\nQuarto Article Layout\n\n\n\nCross References\n\nhtml_document2\npdf_document2\nword_document2\n\n\nQuarto Crossrefs\n\n\n\nWebsites & Blogs\n\nblogdown\ndistill\n\n\nQuarto Websites\nQuarto Blogs\n\n\n\nBooks\n\nbookdown\n\n\nQuarto Books\n\n\n\nInteractivity\nShiny Documents\nQuarto Interactive Documents\n\n\nPaged HTML\npagedown\nSummer 2022\n\n\nJournal Articles\nrticles\nSummer 2022\n\n\nDashboards\nflexdashboard\nFall 2022\n\n\nInteractive Tutorials\nlearnr\nNo equivalent planned\n\n\n\n\n\n\nCan you create custom formats for Quarto like you can for R Markdown?\nNot currently, but we expect that this capability will be available in version 1.0 of Quarto (which will be available before rstudio::conf in July).\n\n\nWhen would be a good time to start new projects in Quarto rather than R Markdown?\nOur current plan is to announce Quarto v1.0 at rstudio::conf (end of July). This will be a stable release that will be an excellent foundation for starting new projects with Quarto or migrating existing R Markdown projects (if you are so inclined).\n\n\nDoes the RStudio IDE support Quarto?\nYes! You need to use the latest release of RStudio (v2022.02), which includes support for editing and preview of Quarto documents.\nYou can download RStudio v2022.02 from https://rstudio.com/products/rstudio/download/.\n\n\nDoes RStudio Connect support Quarto?\nYes! You can publish Quarto content to RStudio Connect v2021.08.0 or later. Quarto has to be enabled as documented in the RStudio Connect admin guide. Connect’s user documentation refers to Quarto.org docs on how to publish from the RStudio IDE. To publish Python-based Quarto content, you can use the rsconnect-python CLI from various locations, including VSCode, JupyterLab or the terminal."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "Open Source License",
    "section": "",
    "text": "The Quarto source code is available at https://github.com/quarto-dev/\nQuarto is a registered trademark of RStudio. Please see our trademark policy for guidelines on usage of the Quarto trademark.\nQuarto also makes use of several other open-source projects, the distribution of which is subject to their respective licenses. Major components and their licenses include:\n\n\n\nProject\nLicense\n\n\n\n\nPandoc\nGNU GPL v2\n\n\nBootstrap 5.0\nMIT\n\n\nBootswatch 5.0\nMIT\n\n\nDeno\nMIT\n\n\nesbuild\nMIT\n\n\nDart Sass\nMIT\n\n\nObservable Runtime\nISC"
  },
  {
    "objectID": "trademark.html",
    "href": "trademark.html",
    "title": "Trademark Policy",
    "section": "",
    "text": "This policy is adapted directly from the WordPress Foundation’s trademark policy for the WordPress and WordCamp names and logos. We admire the job that WordPress has done building a thriving open source community while at the same time making possible a wide variety of WordPress related businesses. We hope that this policy will help us do the same for Quarto."
  },
  {
    "objectID": "trademark.html#goals",
    "href": "trademark.html#goals",
    "title": "Trademark Policy",
    "section": "Goals",
    "text": "Goals\nRStudio, PBC owns and oversees the trademark for the Quarto name and logo. We have developed this trademark usage policy with the following goals in mind:\n\nWe’d like to make it easy for anyone to use the Quarto name or logo for community-oriented efforts that help spread and improve Quarto.\nWe’d like to make it clear how Quarto-related businesses and projects can (and cannot) use the Quarto name and logo.\nWe’d like to make it hard for anyone to use the Quarto name and logo to unfairly profit from, trick or confuse people who are looking for official Quarto resources.\n\nPlease note that it is not the goal of this policy to limit open source or commercial activity around Quarto. We actively encourage Quarto-based open source projects and businesses—our goal with this policy is to prevent confusion about the source of Quarto related software and services."
  },
  {
    "objectID": "trademark.html#permission",
    "href": "trademark.html#permission",
    "title": "Trademark Policy",
    "section": "Permission",
    "text": "Permission\nPermission from RStudio is required to use the Quarto name or logo as part of any project, product, service, domain name, or company name.\nWe will grant permission to use the Quarto name and logo for projects that meet the following criteria:\n\nThe primary purpose of your project is to promote the spread and improvement of the Quarto software.\nYour project is non-commercial in nature (it can make money to cover its costs or contribute to non-profit entities, but it cannot be run as a for-profit project or business).\nYour project neither promotes nor is associated with entities that currently fail to comply with the GPL license under which Quarto is distributed.\n\nIf your project meets these criteria, you will be permitted to use the Quarto name and logo to promote your project in any way you see fit with these exceptions: (1) Please do not use Quarto as part of a domain name; and (2) We do not allow the use of the trademark in advertising, including AdSense/AdWords.\nAll other Quarto-related businesses or projects can use the Quarto name and logo to refer to and explain their services, but they cannot use them as part of a product, project, service, domain name, or company name and they cannot use them in any way that suggests an affiliation with or endorsement by the Quarto open source project.\nThe abbreviation “QMD” is not covered by the Quarto trademark and you are free to use it in any way you see fit."
  },
  {
    "objectID": "trademark.html#examples",
    "href": "trademark.html#examples",
    "title": "Trademark Policy",
    "section": "Examples",
    "text": "Examples\nA consulting company can describe its business as “123 Publishing Services, offering Quarto consulting for publishers,” but cannot call its business “The Quarto Consulting Company.” Similarly, a business related to Quarto extensions can describe itself as “XYZ Extensions, the world’s best Quarto extensions,” but cannot call itself “The Quarto Extension Portal.”\nSimilarly, it’s OK to use the Quarto logo as part of a page that describes your products or services, but it is not OK to use it as part of your company or product logo or branding itself. Under no circumstances is it permitted to use Quarto as part of a domain name or top-level domain name.\nWhen in doubt about your use of the Quarto name or logo, please contact RStudio at permissions@rstudio.com for clarification."
  }
]