---
title: Realistic Nextflow Pipeline
search: true
---

## Overview

This version of the pipeline represents a more realistic use-case of
typical Nextflow bioinformatics pipelines.

-   It has a mixture of Bash, Python and R components
-   The data flow now also features a join, where all events are merged
    into a single event.

Before showing the new Nextflow pipeline, let’s first introduce the
Python and R components.

### Python module: `take_column`

This component subsets an incoming `tsv` file by extracting a certain
column from the file. The `take_column` component is similar to the
`take_second_column` component from the previous section, except we
converted it to Python and made the column an optional parameter.

Contents of `src/vdsl3_tutorial/take_column/`:

<details>
<summary>`config.vsh.yaml`</summary>

``` yaml
functionality:
  name: take_column
  namespace: vdsl3_tutorial
  arguments:
    - name: "--input"
      alternatives: [ "-i" ]
      type: file
      required: true
    - name: "--output"
      alternatives: [ "-o" ]
      type: file
      required: true
      direction: output
    - name: "--column"
      type: integer
      required: false
      default: 2
  resources:
  - type: python_script
    path: ./script.py
platforms:
  - type: nextflow
    variant: vdsl3
    directives:
      container: amancevice/pandas:slim
```

</details>

<details>
<summary>`script.py`</summary>

``` python
import pandas as pd

## VIASH START
par = {
    "input": "data/file1.tsv",
    "column": 2,
    "output": "temp/foo"
}
## VIASH END

# read the tsv file
tab = pd.read_csv(par["input"], sep="\t", comment="#")

# subset a column
tab_filt = tab.iloc[:, par["column"]-1]

# write to file
tab_filt.to_csv(par["output"], index=False)
```

</details>

### R module: `combine_columns`

This component combines multiple `tsv` files into one by concatenating
all of the columns together. It assumes each incoming `tsv` file has an
equal number of rows.

Contents of `src/vdsl3_tutorial/combine_columns/`:

<details>
<summary>`config.vsh.yaml`</summary>

``` yaml
functionality:
  name: combine_columns
  namespace: vdsl3_tutorial
  arguments:
    - name: "--input"
      alternatives: [ "-i" ]
      type: file
      multiple: true
      required: true
    - name: "--output"
      alternatives: [ "-o" ]
      type: file
      required: true
      direction: output
  resources:
    - type: r_script
      path: ./script.R
platforms:
  - type: nextflow
    variant: vdsl3
    directives:
      container: rocker/r-ver:4.1
```

</details>

<details>
<summary>`script.R`</summary>

``` r
## VIASH START
par <- list(
    input = c("data/file1.tsv", "data/file2.tsv"),
    output = "temp/foo.tsv"
)
## VIASH END

outs <- lapply(par$input, function(file) {
  read.delim(file, comment.char = "#", sep = "\t", header = FALSE)
})

table <- do.call(cbind, outs)

write.table(table, par$output, col.names = FALSE, sep = "\t")
```

</details>

### Build all components in one go

In the previous sections, we created three Viash components.

Contents of `src/vdsl3_tutorial/`:

    src/vdsl3_tutorial/
    ├── combine_columns
    │   ├── config.vsh.yaml
    │   └── script.R
    ├── remove_comments
    │   ├── config.vsh.yaml
    │   └── script.sh
    └── take_column
        ├── config.vsh.yaml
        └── script.py

    3 directories, 6 files

Rather than generate VDSL3 modules from each Viash component
individually using the `viash build` command, we can build all of the
components in a namespace (`ns`) using the `viash ns build` command in
one go. The resulting files will be stored under
`target/<platform>/<namespace>/<component_name>`.

``` bash
viash ns build -q vdsl3_tutorial
```

    Exporting take_column (vdsl3_tutorial) =nextflow=> target/nextflow/vdsl3_tutorial/take_column
    Exporting combine_columns (vdsl3_tutorial) =nextflow=> target/nextflow/vdsl3_tutorial/combine_columns
    Exporting remove_comments (vdsl3_tutorial) =nextflow=> target/nextflow/vdsl3_tutorial/remove_comments

The `target` directory now contains our Nextflow modules:

Contents of `target`:

    target/
    └── nextflow
        └── vdsl3_tutorial
            ├── combine_columns
            │   ├── main.nf
            │   └── nextflow.config
            ├── remove_comments
            │   ├── main.nf
            │   └── nextflow.config
            └── take_column
                ├── main.nf
                └── nextflow.config

    5 directories, 6 files

### A branching workflow: keeping track of event types

During a more complicated Nextflow workflow, it can be useful to keep
track of what transformations are being performed at critical steps of
the pipeline. In this case, we simply labelled all steps.

Contents of `workflows/310-realistic_pipeline/main.nf`:

``` groovy
nextflow.enable.dsl=2

targetDir = "../../target/nextflow"

include { remove_comments } from "$targetDir/vdsl3_tutorial/remove_comments/main.nf"
include { take_column } from "$targetDir/vdsl3_tutorial/take_column/main.nf"
include { combine_columns } from "$targetDir/vdsl3_tutorial/combine_columns/main.nf"

workflow {
  Channel.fromPath(params.input)
  
    // Assign unique ID to each event
    //   File -> (String, File)
    | map{ file -> [ file.baseName, file ] }
    
    // Remove comments from TSV
    //   (String, File) -> (String, File)
    | remove_comments

    // Extract single column from TSV
    //   (String, File) -> (String, File)
    | take_column

    // Combine all events into a single List event
    //   (String, File)* -> List[(String, File)]
    | toList()

    // Add unique ID to tuple
    //   List[(String, File)] -> (String, {input: List[File]})
    | map{ tups -> 
      files = tups.collect{id, file -> file}
      [ "combined", [ input: files ] ] 
    }

    // Concatenate TSVs into one
    //   (String, {input: List[File]}) -> (String, File)
    | combine_columns

    // View channel contents
    | view{ file -> "Output: $file" }
}
```

In terms of a marble diagram, the `toList()` operator can be represented
as in [Figure 1](#fig-branching).

<figure>
<img src="300-vdsl3_files/figure-gfm/fig-branching-1.svg"
id="fig-branching"
alt="Figure 1: The data flow of the toList() part of workflows/310-realistic_pipeline/main.nf." />
<figcaption aria-hidden="true">Figure 1: The data flow of the
<code>toList()</code> part of
<code>workflows/310-realistic_pipeline/main.nf</code>.</figcaption>
</figure>

We are dealing with tuples in VDSL3 IO, so the above would turn into:

<figure>
<img src="300-vdsl3_files/figure-gfm/fig-branching2-1.svg"
id="fig-branching2"
alt="Figure 2: The data flow of the toList() in combination with tuples." />
<figcaption aria-hidden="true">Figure 2: The data flow of the
<code>toList()</code> in combination with tuples.</figcaption>
</figure>

### Running the full pipeline

When we run the updated pipeline, we can see that the execution seems to
run correctly.

``` bash
nextflow run workflows/310-realistic_pipeline/main.nf \
  --input "data/file?.tsv" --publishDir output
```

    N E X T F L O W  ~  version 22.04.3
    Launching `workflows/310-realistic_pipeline/main.nf` [peaceful_kare] DSL2 - revision: 65be946be4
    [26/03f3d6] Submitted process > remove_comments:remove_comments_process (2)
    [39/b4aecb] Submitted process > remove_comments:remove_comments_process (1)
    [e9/0e5f7f] Submitted process > take_column:take_column_process (1)
    [cc/f65b62] Submitted process > take_column:take_column_process (2)
    [47/12ee1c] Submitted process > combine_columns:combine_columns_process
    Output: [combined, /home/runner/work/viash_nxf_course/viash_nxf_course/work/47/12ee1cf9a37c5450db605199c8abf7/combined.combine_columns.output]

Each process seems to have finished correctly (exit code 0).

However, no output was created in the output directory. In fact, the
output directory wasn’t even created when running the pipeline.

``` sh
tree output
```

    output [error opening dir]

    0 directories, 0 files

The reason for this is that VDSL3 modules are meant to be **reusable**
components. However, at the time of writing the Viash component
(i.e. the `config.vsh.yaml`) you might not know whether the component is
the last step of the pipeline, so it does not make sense to decide
whether a component’s output will be published or not.

## Benefits of VDSL3

This guide introduced some key concepts of VDSL3 modules. In
comparison to standard Nextflow modules, a VDSL3 module offers:

-   Readable but flexible pipelines
-   Automatic file naming to avoid naming conflicts
-   Flexible directives
-   Easy polylingualism (integrates well with custom Docker container
    builds, see next guide)
-   Free standalone CLI and `--help`
-   Overridable arguments with defaults

One *limitation* of VDSL3 is that Nextflow processes are able to accept
tuples of any format whatsoever, whereas VDLS3 modules have a more rigid
interface (see appendix). However, we argue that this limitation is
actually a benefit, as it makes modules more interchangeable and have
argument defaults.

In the next guide, we’ll see that generating VDSL3 modules is actually
just *one aspect* of Viash.